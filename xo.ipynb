{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b882b91-d702-412a-8c23-dd9ca190002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f129e9-9f51-4ca3-85ed-625870389a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tic-tac-toe game class   \n",
    "class TicTacToe:  \n",
    "    #initialization \n",
    "    def __init__(self):  \n",
    "        self.board = np.zeros(9) \n",
    "        self.done = False \n",
    "        self.winner = None  \n",
    "\n",
    "    #loops through board, output is an array with empty cells \n",
    "    def available_positions(self): \n",
    "        cells = [] \n",
    "        for i in range(9): \n",
    "            if self.board[i] == 0: \n",
    "                cells.append(i) \n",
    "        return cells \n",
    "\n",
    "    #if an element is 0, that cell is open for player to make a move \n",
    "    def make_move(self, position, player): \n",
    "        if self.board[position] == 0: \n",
    "            self.board[position] = player \n",
    "            self.check_winner() \n",
    "            return True  \n",
    "            #place player at available position and check if game is over \n",
    "        #not possible to place player here\n",
    "        return False        \n",
    "\n",
    "    #loop through board and check if the game is over \n",
    "    def check_winner(self):  \n",
    "        #possible ways to win the game \n",
    "        combos = [\n",
    "            [0, 1, 2], [3, 4, 5], [6, 7, 8], #rows \n",
    "            [0, 3, 6], [1, 4, 7], [2, 5, 8], #columns \n",
    "            [0, 4, 8], [2, 4, 6] #diagonals \n",
    "        ]  \n",
    "        \n",
    "        for combo in combos:  \n",
    "            #add elements which are in the possible winning positions \n",
    "            s = self.board[combo[0]] + self.board[combo[1]] + self.board[combo[2]]\n",
    "            #x has won the game \n",
    "            if s == 3: \n",
    "                self.done = True \n",
    "                self.winner = 1 \n",
    "                return  \n",
    "            #o has won the game \n",
    "            elif s == -3: \n",
    "                self.done = True \n",
    "                self.winner = -1 \n",
    "                return \n",
    "        #the board is full but no one has won - draw \n",
    "        if 0 not in self.board: \n",
    "            self.done = True \n",
    "            self.winner = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e39622b6-1fa6-4941-8eb8-d592bc58bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q-learning agent \n",
    "class QLearningAgent: \n",
    "    def __init__(self, alpha=0.3, gamma=0.9, epsilon=0.2): \n",
    "        self.q = {} #key - (board state, next move), value - q_value (how good the move is)\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma \n",
    "        self.epsilon = epsilon \n",
    "\n",
    "    #input - state, action to be taken & output - q_val (default - 0) \n",
    "    def getQ(self, state, action): \n",
    "        return self.q.get((tuple(state), action), 0.0) \n",
    "\n",
    "    #what action to take - random/ based on what has been learnt so far \n",
    "    def choose_action(self, state, moves): \n",
    "        #random move \n",
    "        if random.random() < self.epsilon: \n",
    "            return random.choice(moves)  \n",
    "\n",
    "        #loops through possible moves and finds one with the highest q value \n",
    "        qs = [] \n",
    "        for move in moves: \n",
    "            qs.append(self.getQ(state, move)) \n",
    "        maxQ = max(qs) \n",
    "\n",
    "        #for the highest q_val, what are the corresponding moves \n",
    "        best_moves = [] \n",
    "        for i in range(len(moves)): \n",
    "            move = moves[i] \n",
    "            q_val = qs[i] \n",
    "            if q_val == maxQ: \n",
    "                best_moves.append(move) \n",
    "\n",
    "        return random.choice(best_moves)  \n",
    "\n",
    "    #updates itself after every move \n",
    "    def learn(self, state, action, reward, next_state, next_moves): \n",
    "        old_q = self.getQ(state, action) \n",
    "        if next_moves: \n",
    "            next_qs = [] \n",
    "            for move in next_moves: \n",
    "                next_qs.append(self.getQ(next_state, move)) \n",
    "            max_next_q = max(next_qs) \n",
    "        else: \n",
    "            max_next_q = 0 \n",
    "        #new knowledge = old knowledge + (learning rate * [what actually happened - what was predicted])\n",
    "        new_q = old_q + self.alpha*(reward + self.gamma*max_next_q - old_q) \n",
    "        self.q[(tuple(state), action)] = new_q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ca70384-0264-46f6-ba85-f6c6d910abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function  \n",
    "def train(agent_X, agent_O, episodes=50000): \n",
    "    for _ in range(episodes): \n",
    "        game = TicTacToe() \n",
    "\n",
    "        #X always starts \n",
    "        player = 1  \n",
    "        while not game.done: \n",
    "            state = game.board.copy() \n",
    "            moves = game.available_positions() \n",
    "            if player == 1: \n",
    "                action = agent_X.choose_action(state, moves) \n",
    "            else: \n",
    "                action = agent_O.choose_action(state, moves)  \n",
    "            game.make_move(action, player) \n",
    "            next_state = game.board.copy() \n",
    "            next_moves = game.available_positions() \n",
    "\n",
    "            if game.done: \n",
    "                #draw \n",
    "                if game.winner == 0: \n",
    "                    reward_X = 0.5 \n",
    "                    reward_O = 0.5 \n",
    "                #X wins \n",
    "                elif game.winner == 1: \n",
    "                    reward_X = 1 \n",
    "                    reward_O = 0  \n",
    "                #O wins \n",
    "                else: \n",
    "                    reward_X = 0 \n",
    "                    reward_Y = 1 \n",
    "            else: \n",
    "                reward_X = 0 \n",
    "                reward_O = 0 \n",
    "\n",
    "            #updating q values of X and O  \n",
    "            agent_X.learn(state, action, reward_X, next_state, next_moves) \n",
    "            agent_O.learn(state, action, reward_O, next_state, next_moves) \n",
    "\n",
    "            #switching out the player \n",
    "            player = player*-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cfdceb-a440-48a0-928c-876582f0a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play function   \n",
    "def play(agent): \n",
    "    game = TicTacToe() \n",
    "    #X starts \n",
    "    player = 1  \n",
    "    #game board \n",
    "    print(\"positions:\\n0|1|2\\n3|4|5\\n6|7|8\\n\") \n",
    "\n",
    "    while not game.done: \n",
    "        print(game.board.reshape(3, 3)) \n",
    "        if player == 1: \n",
    "            move = int(input(\"enter your move - 0 to 8\")) \n",
    "        else: \n",
    "            move = agent.choose_action(game.board, game.available_positions()) \n",
    "        game.make_move(move, player) \n",
    "        player = player*-1 \n",
    "\n",
    "    #board when game is done \n",
    "    print(game.board.reshape(3, 3))  \n",
    "\n",
    "    if game.winner == 1: \n",
    "        print(\"you won\") \n",
    "    elif game.winner == -1: \n",
    "        print(\"ai wins\") \n",
    "    else: \n",
    "        print(\"draw\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c956ff7-4e34-408e-b6b5-603a281ed5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training in progress\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "#actually training the agents   \n",
    "agent_X = QLearningAgent() \n",
    "agent_O = QLearningAgent() \n",
    "\n",
    "print(\"training in progress\") \n",
    "train(agent_X, agent_O, episodes=200000) \n",
    "print(\"training complete\")  \n",
    "agent_O.epsilon = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac7b564f-9213-4317-bb02-8351a2da9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions:\n",
      "0|1|2\n",
      "3|4|5\n",
      "6|7|8\n",
      "\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 0.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 1.  0. -1.]]\n",
      "you won\n"
     ]
    }
   ],
   "source": [
    "#actually playing with O   \n",
    "play(agent_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f6929cf-41e2-45fc-b003-520340a631ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions:\n",
      "0|1|2\n",
      "3|4|5\n",
      "6|7|8\n",
      "\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 1. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1. -1.  0.]\n",
      " [-1.  1.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [-1.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "you won\n"
     ]
    }
   ],
   "source": [
    "play(agent_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d532293-893d-4323-9cb1-514ab7695928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions:\n",
      "0|1|2\n",
      "3|4|5\n",
      "6|7|8\n",
      "\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.]\n",
      " [ 1.  0. -1.]\n",
      " [ 0.  0. -1.]]\n",
      "[[ 1.  1.  0.]\n",
      " [ 1.  0. -1.]\n",
      " [-1.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.]\n",
      " [ 1.  1. -1.]\n",
      " [-1.  0. -1.]]\n",
      "[[ 1.  1.  0.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1. -1.]]\n",
      "ai wins\n"
     ]
    }
   ],
   "source": [
    "play(agent_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88c4300e-dc59-4766-94c9-7a57d0da2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions:\n",
      "0|1|2\n",
      "3|4|5\n",
      "6|7|8\n",
      "\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0. -1.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0. -1.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  1.  0.]]\n",
      "[[ 0. -1.  1.]\n",
      " [-1.  1.  0.]\n",
      " [-1.  1.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.  1.]\n",
      " [-1.  1.  0.]\n",
      " [-1.  1.  1.]]\n",
      "[[ 0. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1.  1.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your move - 0 to 8 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1.  1.]]\n",
      "you won\n"
     ]
    }
   ],
   "source": [
    "play(agent_O) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ec37c-935d-4bf2-9bb1-8469bec95883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
